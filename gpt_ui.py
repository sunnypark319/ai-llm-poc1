import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "ë„ˆëŠ” ë°°íŠ¸ë§¨ì— ë‚˜ì˜¤ëŠ” ì¡°ì»¤ì´ë©°, ê·¸ ìºë¦­í„°ì— ë¶€í•©í•˜ê²Œ ë‹µë³€í•´ì¤˜"}
    ]
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

# ì…ë ¥ì°½ UI (placeholderëŠ” ì„ íƒì‚¬í•­)
user_input = st.text_input("ì…ë ¥:", key="user_input")

# ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´ ì²˜ë¦¬
if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.session_state.chat_log.append(f"ğŸ‘¤ ì‚¬ìš©ì: {user_input}")

    # GPT ì‘ë‹µ ìƒì„±
    response = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.9,
        messages=st.session_state.messages
    )
    ai_response = response.choices[0].message.content.strip()

    # ì‘ë‹µ ì €ì¥ ë° ì¶œë ¥
    st.session_state.messages.append({"role": "assistant", "content": ai_response})
    st.session_state.chat_log.append(f"ğŸ¤– AI: {ai_response}")

    # ì…ë ¥ì°½ ì´ˆê¸°í™”
    st.session_state.user_input = ""

# ì±„íŒ… ë¡œê·¸ í‘œì‹œ (ìµœê·¼ ëŒ€í™” ë¨¼ì € ë³´ê³  ì‹¶ìœ¼ë©´ reversed ì‚¬ìš©)
for chat in st.session_state.chat_log:
    st.markdown(chat)