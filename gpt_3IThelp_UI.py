import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import os
import pandas as pd
import json
from pathlib import Path
import PyPDF2
import docx
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle
from datetime import datetime
import tempfile
import shutil

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="IT í—¬í”„ë°ìŠ¤í¬",
    page_icon="ğŸ’»",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        align-items: flex-start;
    }
    .chat-message.user {
        background-color: #e3f2fd;
        flex-direction: row-reverse;
        text-align: right;
    }
    .chat-message.bot {
        background-color: #f5f5f5;
    }
    .chat-message .avatar {
        width: 40px;
        height: 40px;
        border-radius: 50%;
        margin: 0 1rem;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 1.2rem;
    }
    .chat-message .message {
        flex-grow: 1;
        padding: 0.5rem;
    }
    .sidebar-content {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .quick-help {
        background-color: #e8f5e8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #4caf50;
    }
</style>
""", unsafe_allow_html=True)

load_dotenv()

# ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (ìˆ˜ì • ë²„ì „)
class DocumentRAG:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = None
        self.model_name = model_name
        self.documents = []
        self.embeddings = []
        self.doc_metadata = []
        
    def _initialize_model(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (í•„ìš”ì‹œì—ë§Œ)"""
        if self.embedding_model is None:
            with st.spinner('ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                self.embedding_model = SentenceTransformer(self.model_name)
    
    def load_documents_from_files(self, uploaded_files):
        """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
        self.documents = []
        self.doc_metadata = []
        
        progress_bar = st.progress(0)
        total_files = len(uploaded_files)
        
        for idx, uploaded_file in enumerate(uploaded_files):
            try:
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded_file.name}") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                # íŒŒì¼ ì½ê¸°
                content = self._read_file(Path(tmp_file_path))
                if content and len(content.strip()) > 50:
                    chunks = self._split_text(content, chunk_size=800, overlap=150)
                    for i, chunk in enumerate(chunks):
                        if len(chunk.strip()) > 30:
                            self.documents.append(chunk)
                            self.doc_metadata.append({
                                'file_name': uploaded_file.name,
                                'chunk_id': i,
                                'total_chunks': len(chunks),
                                'file_type': Path(uploaded_file.name).suffix.lower()
                            })
                    st.sidebar.success(f"âœ… {uploaded_file.name}: {len(chunks)}ê°œ ì²­í¬")
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.unlink(tmp_file_path)
                
            except Exception as e:
                st.sidebar.error(f"âŒ {uploaded_file.name}: {str(e)}")
            
            progress_bar.progress((idx + 1) / total_files)
        
        st.sidebar.info(f"ğŸ“š ì´ {len(self.documents)}ê°œì˜ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
        return len(self.documents) > 0
    
    def _read_file(self, file_path):
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì½ê¸°"""
        extension = file_path.suffix.lower()
        
        try:
            if extension == '.txt':
                for encoding in ['utf-8', 'cp949', 'euc-kr', 'latin-1']:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            return f.read()
                    except UnicodeDecodeError:
                        continue
                return None
                
            elif extension == '.pdf':
                with open(file_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    text = ''
                    for page in reader.pages:
                        text += page.extract_text() + '\n'
                    return text
                    
            elif extension == '.docx':
                doc = docx.Document(file_path)
                return '\n'.join([paragraph.text for paragraph in doc.paragraphs])
                
            elif extension == '.csv':
                df = pd.read_csv(file_path)
                return df.to_string()
                
            elif extension == '.json':
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return json.dumps(data, ensure_ascii=False, indent=2)
        
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return None
        
        return None
    
    def _split_text(self, text, chunk_size=800, overlap=150):
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        chunks = []
        sections = text.split('\n\n')
        current_chunk = ""
        
        for section in sections:
            if len(current_chunk) + len(section) < chunk_size:
                current_chunk += section + '\n\n'
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = section + '\n\n'
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def create_embeddings(self):
        """ë¬¸ì„œë“¤ì˜ ì„ë² ë”© ìƒì„±"""
        if not self.documents:
            return False
        
        self._initialize_model()
        with st.spinner('ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
            self.embeddings = self.embedding_model.encode(self.documents, show_progress_bar=False)
        return True
    
    def search_similar_documents(self, query, top_k=4):
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰(ê°•í™”)"""
            
        if not self.documents or len(self.embeddings) == 0:
            st.write("âŒ ë¬¸ì„œë‚˜ ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        self._initialize_model()
        query_embedding = self.embedding_model.encode([query])
        similarities = cosine_similarity(query_embedding, self.embeddings)[0]
        
        # ë””ë²„ê¹…: ëª¨ë“  ìœ ì‚¬ë„ ì ìˆ˜ í™•ì¸
        st.write(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
        st.write(f"ğŸ“Š ìœ ì‚¬ë„ ì ìˆ˜ ë¶„í¬:")
        
        # íŒŒì¼ë³„ ìµœê³  ìœ ì‚¬ë„ í™•ì¸
        file_max_scores = {}
        for i, (sim, meta) in enumerate(zip(similarities, self.doc_metadata)):
            file_name = meta['file_name']
            if file_name not in file_max_scores or sim > file_max_scores[file_name]['score']:
                file_max_scores[file_name] = {'score': sim, 'index': i}
        
        for file_name, info in file_max_scores.items():
            st.write(f"ğŸ“„ {file_name}: ìµœê³  ìœ ì‚¬ë„ {info['score']:.3f}")
        
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        #st.write(f"\nğŸ¯ ìƒìœ„ {top_k}ê°œ ê²°ê³¼:")
        for rank, idx in enumerate(top_indices):
            score = similarities[idx]
            #st.write(f"{rank+1}. {self.doc_metadata[idx]['file_name']} - ìœ ì‚¬ë„: {score:.3f}")
            
            if score > 0.1:  # ì„ê³„ê°’ì„ 0.2ì—ì„œ 0.1ë¡œ ë‚®ì¶¤
                results.append({
                    'content': self.documents[idx],
                    'similarity': score,
                    'metadata': self.doc_metadata[idx]
                })
        
        return results
    

    def check_loaded_documents(self):  # ì´ ë©”ì„œë“œë¥¼ ì¶”ê°€
        """ë¡œë“œëœ ë¬¸ì„œ ìƒíƒœ í™•ì¸"""
        st.write("=== ë¡œë“œëœ ë¬¸ì„œ ë””ë²„ê¹… ì •ë³´ ===")
        st.write(f"ì´ ë¬¸ì„œ ì²­í¬ ìˆ˜: {len(self.documents)}")
            
        # íŒŒì¼ë³„ ì²­í¬ ìˆ˜ í™•ì¸
        file_counts = {}
        for metadata in self.doc_metadata:
            file_name = metadata['file_name']
            file_counts[file_name] = file_counts.get(file_name, 0) + 1
            
        for file_name, count in file_counts.items():
            st.write(f"ğŸ“„ {file_name}: {count}ê°œ ì²­í¬")
            
        # ê° ë¬¸ì„œì˜ ì¼ë¶€ ë‚´ìš© í™•ì¸
        st.write("\n=== ë¬¸ì„œ ë‚´ìš© ìƒ˜í”Œ ===")
        for i, (doc, meta) in enumerate(zip(self.documents[:5], self.doc_metadata[:5])):
            st.write(f"**ì²­í¬ {i+1} ({meta['file_name']}):**")
            st.write(doc[:200] + "..." if len(doc) > 200 else doc)
            st.write("---")

class ITHelpdeskWebApp:
    def __init__(self):
        self.rag = DocumentRAG()
        self.client = None
        self._initialize_openai()
        
    def _initialize_openai(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        
        api_key = st.secrets["OPENAI_API_KEY"]
        if not api_key:
            st.error("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEY=your_api_key_here ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
            return False
        
        try:
            self.client = OpenAI(api_key=api_key)
            return True
        except Exception as e:
            st.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def get_system_message(self):
        """ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë°˜í™˜"""
        return {
            "role": "system", 
            "content": """ë‹¹ì‹ ì€ ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ IT í—¬í”„ë°ìŠ¤í¬ ì§€ì› ë‹´ë‹¹ìì…ë‹ˆë‹¤. 
            ì§ì›ë“¤ì˜ IT ê´€ë ¨ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ê¸°ìˆ  ì§€ì›ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ì£¼ëœ ì—­í• ì…ë‹ˆë‹¤.
            
            ì£¼ìš” ë‹´ë‹¹ ì—…ë¬´:
            â€¢ í•˜ë“œì›¨ì–´ ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²° (PC, ë…¸íŠ¸ë¶, í”„ë¦°í„°, ëª¨ë‹ˆí„° ë“±)
            â€¢ ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜, ì—…ë°ì´íŠ¸, ì˜¤ë¥˜ í•´ê²°
            â€¢ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ (Wi-Fi, ìœ ì„ , VPN)
            â€¢ ì´ë©”ì¼ ë° ê³„ì • ê´€ë ¨ ë¬¸ì œ
            â€¢ ë³´ì•ˆ ì†Œí”„íŠ¸ì›¨ì–´ ë° ë°”ì´ëŸ¬ìŠ¤ ê´€ë ¨ ì§€ì›
            â€¢ íŒŒì¼ ê³µìœ  ë° ë°±ì—… ë¬¸ì œ
            â€¢ ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì • ë° ê³„ì • ì ê¸ˆ í•´ì œ
            â€¢ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ì„ ìŠ¤ ë° ì„¤ì¹˜ ê°€ì´ë“œ
            â€¢ ì›ê²© ê·¼ë¬´ ê¸°ìˆ  ì§€ì›
            â€¢ ëª¨ë°”ì¼ ê¸°ê¸° ë° ì•± ì„¤ì •
            â€¢ í™”ìƒíšŒì˜ ë„êµ¬ ì‚¬ìš©ë²•
            â€¢ ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™”
            â€¢ ë°ì´í„° ë³µêµ¬ ë° ë§ˆì´ê·¸ë ˆì´ì…˜
            â€¢ IT ì •ì±… ë° ë³´ì•ˆ ê°€ì´ë“œë¼ì¸ ì•ˆë‚´
            
            ë‹µë³€ ê°€ì´ë“œë¼ì¸:
            1. ì œê³µëœ IT ê´€ë ¨ ë¬¸ì„œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ì •í™•í•œ í•´ê²°ì±… ì œê³µ
            2. ë‹¨ê³„ë³„ë¡œ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í•´ê²° ë°©ë²• ì•ˆë‚´
            3. ìŠ¤í¬ë¦°ìƒ·ì´ë‚˜ êµ¬ì²´ì ì¸ ë©”ë‰´ ê²½ë¡œ í¬í•¨í•˜ì—¬ ì„¤ëª…
            4. ë³´ì•ˆ ê´€ë ¨ ì‚¬í•­ì€ ë°˜ë“œì‹œ ê°•ì¡°í•˜ì—¬ ì•ˆë‚´
            5. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¼ë°˜ì ì¸ IT ì§€ì‹ìœ¼ë¡œ ë„ì›€ ì œê³µ
            6. í•˜ë“œì›¨ì–´ êµì²´ë‚˜ ë³µì¡í•œ ë¬¸ì œëŠ” í˜„ì¥ ì§€ì›íŒ€ ì—°ê²° ì•ˆë‚´
            7. ì‘ê¸‰ ìƒí™© ì‹œ ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ëŒ€ì‘ ë°©ë²• ì œì‹œ
            8. ì˜ˆë°©ì±…ê³¼ ëª¨ë²” ì‚¬ë¡€ë„ í•¨ê»˜ ì•ˆë‚´
            9. ì›ê²© ì§€ì›ì´ í•„ìš”í•œ ê²½ìš° ê´€ë ¨ ë„êµ¬ ì‚¬ìš©ë²• ì•ˆë‚´
            
            ë§íˆ¬: ê¸°ìˆ ì ì´ë©´ì„œë„ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ, ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ë˜ 
            ì‚¬ìš©ìì˜ ê¸°ìˆ  ìˆ˜ì¤€ì— ë§ì¶° ì ì ˆí•œ ìš©ì–´ ì‚¬ìš©"""
        }
    
    def get_context_from_documents(self, user_input):
        """ì‚¬ìš©ì ì…ë ¥ê³¼ ê´€ë ¨ëœ IT ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        if not self.rag.documents:
            return ""
        
        similar_docs = self.rag.search_similar_documents(user_input, top_k=4)
        
        if not similar_docs:
            return ""
        
        context = "=== ê´€ë ¨ IT ë¬¸ì„œ ë° ë§¤ë‰´ì–¼ ===\n\n"
        for i, doc in enumerate(similar_docs):
            context += f"[ì°¸ê³ ë¬¸ì„œ {i+1}] {doc['metadata']['file_name']}:\n"
            context += f"{doc['content']}\n"
            context += f"(ê´€ë ¨ë„: {doc['similarity']:.0%})\n\n"
        
        context += "=== ìœ„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš” ===\n"
        return context, similar_docs
    
    def generate_response(self, user_input, conversation_history):
        """AI ì‘ë‹µ ìƒì„±"""
        if not self.client:
            return "âŒ OpenAI ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        context_result = self.get_context_from_documents(user_input)
        context = ""
        similar_docs = []
        
        if context_result:
            context, similar_docs = context_result
        
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [self.get_system_message()]
        
        # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 5ê°œë§Œ)
        for conv in conversation_history[-5:]:
            messages.append({"role": "user", "content": conv["user"]})
            messages.append({"role": "assistant", "content": conv["assistant"]})
        
        # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
        if context:
            enhanced_input = f"{context}\n\nì‚¬ìš©ì ë¬¸ì œ: {user_input}"
        else:
            enhanced_input = user_input
        
        messages.append({"role": "user", "content": enhanced_input})
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                temperature=0.3,
                messages=messages,
                max_tokens=1200
            )
            
            ai_response = response.choices[0].message.content
            return ai_response, similar_docs
            
        except Exception as e:
            return f"âŒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", []

def main():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'app' not in st.session_state:
        st.session_state.app = ITHelpdeskWebApp()
    
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []
    
    if 'documents_loaded' not in st.session_state:
        st.session_state.documents_loaded = False
    
    # í—¤ë”
    st.title("ğŸ’» IT í—¬í”„ë°ìŠ¤í¬")
    st.markdown("IT ê´€ë ¨ ë¬¸ì œë¥¼ í•´ê²°í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ğŸ› ï¸")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        uploaded_files = st.file_uploader(
            "IT ê´€ë ¨ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['txt', 'pdf', 'docx', 'csv', 'json'],
            accept_multiple_files=True,
            help="ë§¤ë‰´ì–¼, ê°€ì´ë“œ, ì •ì±… ë¬¸ì„œ ë“±ì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        if uploaded_files and not st.session_state.documents_loaded:
            if st.button("ğŸ“š ë¬¸ì„œ ë¡œë“œ ë° ì„ë² ë”© ìƒì„±"):
                if st.session_state.app.rag.load_documents_from_files(uploaded_files):
                    if st.session_state.app.rag.create_embeddings():
                        st.session_state.documents_loaded = True
                        st.success("âœ… ë¬¸ì„œ ë¡œë“œ ë° ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
                        st.rerun()
        
        # ë¬¸ì„œ ìƒíƒœ í‘œì‹œ
        st.markdown("---")
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        
        if st.session_state.documents_loaded:
            st.success(f"ğŸ“š ë¡œë“œëœ ë¬¸ì„œ: {len(st.session_state.app.rag.documents)}ê°œ ì²­í¬")
        else:
            st.info("ğŸ“ ë¬¸ì„œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        if st.session_state.app.client:
            st.success("ğŸ¤– OpenAI ì—°ê²°: ì •ìƒ")
        else:
            st.error("âŒ OpenAI ì—°ê²°: ì‹¤íŒ¨")

        # ë””ë²„ê¹… ì„¹ì…˜
        st.markdown("---")
        st.subheader("ğŸ” ë””ë²„ê¹… ë„êµ¬")
        
        if st.button("ğŸ“‹ ë¡œë“œëœ ë¬¸ì„œ í™•ì¸"):
            if st.session_state.documents_loaded:
                st.session_state.app.rag.check_loaded_documents()
            else:
                st.warning("ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        if st.button("ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"):
            if st.session_state.documents_loaded:
                test_query = st.text_input("í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ì–´:", value="ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì •")
                if test_query:
                    st.write(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'")
                    results = st.session_state.app.rag.search_similar_documents(test_query, top_k=10)
                    st.write(f"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}")
            else:
                st.warning("ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
        st.markdown("---")
        st.subheader("ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
        
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.conversation_history = []
            st.rerun()
        
        st.info(f"ëŒ€í™” ìˆ˜: {len(st.session_state.conversation_history)}")
        
        # ìì£¼ ë¬»ëŠ” ì§ˆë¬¸
        st.markdown("---")
        st.markdown("""
        <div class="quick-help">
        <h4>ğŸ” ìì£¼ ë¬»ëŠ” ì§ˆë¬¸</h4>
        <ul>
        <li>ğŸ”‘ "ë¹„ë°€ë²ˆí˜¸ë¥¼ ì¬ì„¤ì •í•˜ê³  ì‹¶ì–´ìš”"</li>
        <li>ğŸ“¶ "Wi-Fi ì—°ê²°ì´ ì•ˆ ë¼ìš”"</li>
        <li>ğŸ–¨ï¸ "í”„ë¦°í„° ì„¤ì •ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"</li>
        <li>ğŸ“§ "ì´ë©”ì¼ ì„¤ì •ì„ ë„ì™€ì£¼ì„¸ìš”"</li>
        <li>ğŸ’¾ "íŒŒì¼ì„ ë³µêµ¬í•  ìˆ˜ ìˆë‚˜ìš”?"</li>
        <li>ğŸ›¡ï¸ "ë°”ì´ëŸ¬ìŠ¤ì— ê°ì—¼ëœ ê²ƒ ê°™ì•„ìš”"</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    st.markdown("---")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for conv in st.session_state.conversation_history:
        # ì‚¬ìš©ì ë©”ì‹œì§€
        with st.chat_message("user"):
            st.write(conv['user'])
        
        # AI ì‘ë‹µ
        with st.chat_message("assistant", avatar="ğŸ’»"):
            st.write(conv['assistant'])
            
            # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
            if 'sources' in conv and conv['sources']:
                with st.expander("ğŸ“‹ ì°¸ê³  ë¬¸ì„œ"):
                    for doc in conv['sources']:
                        st.write(f"ğŸ“„ **{doc['metadata']['file_name']}** (ê´€ë ¨ë„: {doc['similarity']:.0%})")
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("IT ë¬¸ì œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”... (ì˜ˆ: ì»´í“¨í„°ê°€ ì¼œì§€ì§€ ì•Šì•„ìš”)"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ
        with st.chat_message("user"):
            st.write(prompt)
        
        # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        with st.chat_message("assistant", avatar="ğŸ’»"):
            with st.spinner("í•´ê²°ì±…ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
                response_data = st.session_state.app.generate_response(
                    prompt, 
                    st.session_state.conversation_history
                )
                
                if len(response_data) == 2:
                    ai_response, similar_docs = response_data
                else:
                    ai_response = response_data
                    similar_docs = []
                
                st.write(ai_response)
                
                # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
                if similar_docs:
                    with st.expander("ğŸ“‹ ì°¸ê³  ë¬¸ì„œ"):
                        for doc in similar_docs:
                            st.write(f"ğŸ“„ **{doc['metadata']['file_name']}** (ê´€ë ¨ë„: {doc['similarity']:.0%})")
                
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                conversation_entry = {
                    "user": prompt,
                    "assistant": ai_response,
                    "timestamp": datetime.now().isoformat(),
                    "sources": similar_docs
                }
                
                st.session_state.conversation_history.append(conversation_entry)
    
    # í™˜ì˜ ë©”ì‹œì§€ (ëŒ€í™”ê°€ ì—†ì„ ë•Œë§Œ)
    if not st.session_state.conversation_history:
        with st.chat_message("assistant", avatar="ğŸ’»"):
            st.write("ì•ˆë…•í•˜ì„¸ìš”! IT í—¬í”„ë°ìŠ¤í¬ì…ë‹ˆë‹¤. IT ê´€ë ¨ ë¬¸ì œê°€ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ› ï¸")
            st.info("ğŸ’¡ **íŒ:** ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ IT ë§¤ë‰´ì–¼ì´ë‚˜ ê°€ì´ë“œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì‹œë©´ ë” ì •í™•í•œ í•´ê²°ì±…ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()