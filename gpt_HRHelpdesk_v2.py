
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import os
import pandas as pd
import json
from pathlib import Path
import PyPDF2
import docx
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle
from datetime import datetime
import tempfile
import shutil

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="HR í—¬í”„ë°ìŠ¤í¬",
    page_icon="ğŸ‘¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        align-items: flex-start;
    }
    .chat-message.user {
        background-color: #e3f2fd;
        flex-direction: row-reverse;
        text-align: right;
    }
    .chat-message.bot {
        background-color: #f5f5f5;
    }
    .chat-message .avatar {
        width: 40px;
        height: 40px;
        border-radius: 50%;
        margin: 0 1rem;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 1.2rem;
    }
    .chat-message .message {
        flex-grow: 1;
        padding: 0.5rem;
    }
    .sidebar-content {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .quick-help {
        background-color: #e8f5e8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #4caf50;
    }
</style>
""", unsafe_allow_html=True)

load_dotenv()

# ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (ìˆ˜ì • ë²„ì „)
class DocumentRAG:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.embedding_model = None
        self.model_name = model_name
        self.documents = []
        self.embeddings = []
        self.doc_metadata = []
        
    def _initialize_model(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (í•„ìš”ì‹œì—ë§Œ)"""
        if self.embedding_model is None:
            with st.spinner('ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                self.embedding_model = SentenceTransformer(self.model_name)
    
    def load_documents_from_files(self, uploaded_files):
        """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
        self.documents = []
        self.doc_metadata = []
        
        progress_bar = st.progress(0)
        total_files = len(uploaded_files)
        
        for idx, uploaded_file in enumerate(uploaded_files):
            try:
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded_file.name}") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                # íŒŒì¼ ì½ê¸°
                content = self._read_file(Path(tmp_file_path))
                if content and len(content.strip()) > 50:
                    chunks = self._split_text(content, chunk_size=800, overlap=150)
                    for i, chunk in enumerate(chunks):
                        if len(chunk.strip()) > 30:
                            self.documents.append(chunk)
                            self.doc_metadata.append({
                                'file_name': uploaded_file.name,
                                'chunk_id': i,
                                'total_chunks': len(chunks),
                                'file_type': Path(uploaded_file.name).suffix.lower()
                            })
                    st.sidebar.success(f"âœ… {uploaded_file.name}: {len(chunks)}ê°œ ì²­í¬")
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.unlink(tmp_file_path)
                
            except Exception as e:
                st.sidebar.error(f"âŒ {uploaded_file.name}: {str(e)}")
            
            progress_bar.progress((idx + 1) / total_files)
        
        st.sidebar.info(f"ğŸ“š ì´ {len(self.documents)}ê°œì˜ ë¬¸ì„œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
        return len(self.documents) > 0
    
    def _read_file(self, file_path):
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì½ê¸°"""
        extension = file_path.suffix.lower()
        
        try:
            if extension == '.txt':
                for encoding in ['utf-8', 'cp949', 'euc-kr', 'latin-1']:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            return f.read()
                    except UnicodeDecodeError:
                        continue
                return None
                
            elif extension == '.pdf':
                with open(file_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    text = ''
                    for page in reader.pages:
                        text += page.extract_text() + '\n'
                    return text
                    
            elif extension == '.docx':
                doc = docx.Document(file_path)
                return '\n'.join([paragraph.text for paragraph in doc.paragraphs])
                
            elif extension == '.csv':
                df = pd.read_csv(file_path)
                return df.to_string()
                
            elif extension == '.json':
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return json.dumps(data, ensure_ascii=False, indent=2)
        
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return None
        
        return None
    
    def _split_text(self, text, chunk_size=800, overlap=150):
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        chunks = []
        sections = text.split('\n\n')
        current_chunk = ""
        
        for section in sections:
            if len(current_chunk) + len(section) < chunk_size:
                current_chunk += section + '\n\n'
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = section + '\n\n'
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def create_embeddings(self):
        """ë¬¸ì„œë“¤ì˜ ì„ë² ë”© ìƒì„±"""
        if not self.documents:
            return False
        
        self._initialize_model()
        with st.spinner('ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
            self.embeddings = self.embedding_model.encode(self.documents, show_progress_bar=False)
        return True
    
    def search_similar_documents(self, query, top_k=4):
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.documents or len(self.embeddings) == 0:
            return []
        
        self._initialize_model()
        query_embedding = self.embedding_model.encode([query])
        similarities = cosine_similarity(query_embedding, self.embeddings)[0]
        
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            if similarities[idx] > 0.2:
                results.append({
                    'content': self.documents[idx],
                    'similarity': similarities[idx],
                    'metadata': self.doc_metadata[idx]
                })
        
        return results

class HRHelpdeskWebApp:
    def __init__(self):
        self.rag = DocumentRAG()
        self.client = None
        self._initialize_openai()
        self.hr_term_mapping = self._setup_hr_terms()
        
    def _initialize_openai(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            st.error("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEY=your_api_key_here ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
            return False
        
        try:
            self.client = OpenAI(api_key=api_key)
            return True
        except Exception as e:
            st.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _setup_hr_terms(self):
        """HR ê´€ë ¨ ìš©ì–´ ë§¤í•‘ ì„¤ì •"""
        return {
            # íœ´ê°€ ê´€ë ¨
            "ì—°ì°¨": ["ìœ ê¸‰íœ´ê°€", "annual leave", "paid leave", "ì—°ì°¨íœ´ê°€", "ë…„ì°¨", "íœ´ê°€"],
            "ë³‘ê°€": ["sick leave", "ë³‘íœ´", "ë³‘ê°€íœ´ê°€", "ì§ˆë³‘íœ´ê°€"],
            "ì¶œì‚°íœ´ê°€": ["maternity leave", "ìœ¡ì•„íœ´ì§", "ì‚°ì „í›„íœ´ê°€", "ì‚°íœ´"],
            "ê²½ì¡°ì‚¬íœ´ê°€": ["bereavement leave", "ê²½ì¡°íœ´ê°€", "ì¡°ì˜íœ´ê°€"],
            "ë°˜ì°¨": ["half day", "ë°˜ì¼íœ´ê°€", "ì˜¤ì „ë°˜ì°¨", "ì˜¤í›„ë°˜ì°¨"],
            
            # ê¸‰ì—¬ ê´€ë ¨
            "ê¸‰ì—¬": ["salary", "ì›”ê¸‰", "ì„ê¸ˆ", "ë´‰ê¸‰", "í˜ì´"],
            "ìƒì—¬ê¸ˆ": ["bonus", "ë³´ë„ˆìŠ¤", "ìƒì—¬", "ì„±ê³¼ê¸‰"],
            "ì•¼ê·¼ìˆ˜ë‹¹": ["overtime pay", "ì´ˆê³¼ê·¼ë¬´ìˆ˜ë‹¹", "ì—°ì¥ê·¼ë¬´ìˆ˜ë‹¹", "ì•¼ê·¼ë¹„"],
            "ìˆ˜ë‹¹": ["allowance", "ì§€ì›ê¸ˆ", "ë³´ì¡°ê¸ˆ"],
            "ì„¸ê¸ˆ": ["tax", "ì†Œë“ì„¸", "ì§€ë°©ì†Œë“ì„¸", "êµ­ë¯¼ì—°ê¸ˆ", "ê±´ê°•ë³´í—˜"],
            
            # ë³µë¦¬í›„ìƒ ê´€ë ¨
            "ë³µë¦¬í›„ìƒ": ["benefits", "welfare", "ë³µì§€", "í˜œíƒ", "ì§€ì›ì œë„"],
            "ê±´ê°•ê²€ì§„": ["health checkup", "ì¢…í•©ê²€ì§„", "ì˜ë£Œê²€ì§„"],
            "í•™ìê¸ˆ": ["tuition support", "êµìœ¡ë¹„", "ë“±ë¡ê¸ˆ", "í•™ë¹„ì§€ì›"],
            "ë™í˜¸íšŒ": ["club", "ì†Œëª¨ì„", "ì·¨ë¯¸í™œë™"],
            
            # ì¸ì‚¬í‰ê°€ ê´€ë ¨
            "ì¸ì‚¬í‰ê°€": ["performance review", "í‰ê°€", "ê³ ê³¼", "ì„±ê³¼í‰ê°€"],
            "ìŠ¹ì§„": ["promotion", "ì§„ê¸‰", "ì§ê¸‰ìƒìŠ¹"],
            "êµìœ¡": ["training", "ì—°ìˆ˜", "êµìœ¡ê³¼ì •", "ìŠ¤í‚¬ì—…"],
            
            # ì¡°ì§ ê´€ë ¨
            "ì¡°ì§ë„": ["organization chart", "ì¡°ì§êµ¬ì¡°", "ë¶€ì„œêµ¬ì¡°"],
            "ì¸ì‚¬ì´ë™": ["personnel transfer", "ì „ë³´", "ë°œë ¹", "ë¶€ì„œì´ë™"],
            "í‡´ì§": ["resignation", "ì‚¬ì§", "í‡´ì‚¬", "ì€í‡´"],
            
            # ê·¼ë¬´ ê´€ë ¨
            "ê·¼ë¬´ì‹œê°„": ["working hours", "ì—…ë¬´ì‹œê°„", "ì¶œí‡´ê·¼ì‹œê°„"],
            "ì¬íƒê·¼ë¬´": ["remote work", "í™ˆì˜¤í”¼ìŠ¤", "ì›ê²©ê·¼ë¬´", "í…”ë ˆì›Œí¬"],
            "ìœ ì—°ê·¼ë¬´": ["flexible work", "íƒ„ë ¥ê·¼ë¬´", "ì„ íƒê·¼ë¬´"],
        }
    
    def expand_query_with_terms(self, user_input):
        """ì‚¬ìš©ì ì…ë ¥ì„ HR ìš©ì–´ë¡œ í™•ì¥"""
        expanded_terms = []
        original_input = user_input.lower()
        
        # ì›ë³¸ ì…ë ¥ ì¶”ê°€
        expanded_terms.append(user_input)
        
        # ë§¤í•‘ëœ ìš©ì–´ë“¤ ì¶”ê°€
        for key_term, related_terms in self.hr_term_mapping.items():
            if key_term in original_input:
                expanded_terms.extend(related_terms)
            else:
                # ê´€ë ¨ ìš©ì–´ê°€ ì…ë ¥ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í•µì‹¬ ìš©ì–´ë„ ì¶”ê°€
                for related_term in related_terms:
                    if related_term in original_input:
                        expanded_terms.append(key_term)
                        expanded_terms.extend(related_terms)
                        break
        
        # ì¤‘ë³µ ì œê±° ë° í™•ì¥ëœ ì¿¼ë¦¬ ìƒì„±
        unique_terms = list(set(expanded_terms))
        
        if len(unique_terms) > 1:
            expanded_query = f"{user_input} {' '.join(unique_terms[:5])}"  # ìµœëŒ€ 5ê°œ ìš©ì–´ ì¶”ê°€
            return expanded_query
        
        return user_input
    
    def get_system_message(self):
        """ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë°˜í™˜"""
        return {
            "role": "system", 
            "content": """ë‹¹ì‹ ì€ ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ HR(ì¸ì‚¬) í—¬í”„ë°ìŠ¤í¬ ë‹´ë‹¹ìì…ë‹ˆë‹¤. 
            ì§ì›ë“¤ì˜ ì¸ì‚¬ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì„ í•´ê²°í•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ ì£¼ëœ ì—­í• ì…ë‹ˆë‹¤.
            
            ì£¼ìš” ë‹´ë‹¹ ì—…ë¬´:
            â€¢ ê¸‰ì—¬, ìˆ˜ë‹¹, ì„¸ê¸ˆ ê´€ë ¨ ë¬¸ì˜
            â€¢ ì—°ì°¨, ë³‘ê°€, íœ´ê°€ ì •ì±… ì•ˆë‚´
            â€¢ ë³µë¦¬í›„ìƒ ì œë„ ì„¤ëª…
            â€¢ ì¸ì‚¬í‰ê°€, ìŠ¹ì§„ ê´€ë ¨ ì •ë³´
            â€¢ êµìœ¡/í›ˆë ¨ í”„ë¡œê·¸ë¨ ì•ˆë‚´
            â€¢ íšŒì‚¬ ì •ì±… ë° ê·œì • ì„¤ëª…
            â€¢ ì¡°ì§ ë³€ê²½, ì¸ì‚¬ì´ë™ ê´€ë ¨ ì•ˆë‚´
            â€¢ í‡´ì§, ì „ì§ ê´€ë ¨ ì ˆì°¨
            â€¢ ì§ì¥ ë‚´ ê³ ì¶© ìƒë‹´
            â€¢ ì‹ ì…ì‚¬ì› ì˜¨ë³´ë”© ì§€ì›
            
            ë‹µë³€ ê°€ì´ë“œë¼ì¸:
            1. ì œê³µëœ íšŒì‚¬ HR ë¬¸ì„œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ì •í™•í•œ ì •ë³´ ì œê³µ
            2. ë¯¼ê°í•œ ê°œì¸ì •ë³´ëŠ” ì§ì ‘ ì²˜ë¦¬í•˜ì§€ ì•Šê³  ë‹´ë‹¹ ë¶€ì„œ ì—°ê²° ì•ˆë‚´
            3. ì •ì±…ì´ë‚˜ ê·œì •ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
            4. ì ˆì°¨ê°€ ë³µì¡í•œ ê²½ìš° ë‹¨ê³„ë³„ë¡œ ì¹œì ˆí•˜ê²Œ ì•ˆë‚´
            5. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¼ë°˜ì ì¸ HR ì§€ì‹ìœ¼ë¡œ ë„ì›€ ì œê³µ
            6. í•­ìƒ ê³µì •í•˜ê³  ì¼ê´€ëœ ì •ë³´ ì œê³µ
            7. í•„ìš”ì‹œ ê´€ë ¨ ë¶€ì„œë‚˜ ë‹´ë‹¹ì ì—°ê²° ì•ˆë‚´
            8. ë¹„ë°€ìœ ì§€ì™€ ê°œì¸ì •ë³´ ë³´í˜¸ ì¤€ìˆ˜
            
            ë§íˆ¬: ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ, ê³µê°ì ì¸ í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ë˜ 
            íšŒì‚¬ì˜ í’ˆê²©ì„ ìœ ì§€í•˜ëŠ” ì •ì¤‘í•œ ì–¸ì–´ ì‚¬ìš©
            
            â­ ì¤‘ìš”: ë‹¤ìŒ í•œêµ­ì–´ HR ìš©ì–´ë“¤ì„ ì •í™•íˆ ì´í•´í•˜ê³  ì‘ë‹µí•˜ì„¸ìš”:
            - "ì—°ì°¨" = ìœ ê¸‰íœ´ê°€, annual leave
            - "ë³‘ê°€" = ë³‘íœ´, sick leave  
            - "ê¸‰ì—¬" = ì›”ê¸‰, ì„ê¸ˆ, salary
            - "ìƒì—¬ê¸ˆ" = ë³´ë„ˆìŠ¤, bonus
            - "ì•¼ê·¼ìˆ˜ë‹¹" = ì´ˆê³¼ê·¼ë¬´ìˆ˜ë‹¹, overtime pay
            - "ë³µë¦¬í›„ìƒ" = ë³µì§€í˜œíƒ, benefits
            - "ì¸ì‚¬í‰ê°€" = ì„±ê³¼í‰ê°€, performance review
            - "ìŠ¹ì§„" = ì§„ê¸‰, promotion
            
            ì‚¬ìš©ìê°€ "ì—°ì°¨"ë¼ê³  ë¬¼ì–´ë³´ë©´ ìœ ê¸‰íœ´ê°€ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ ,
            "ë³‘ê°€"ë¼ê³  ë¬¼ì–´ë³´ë©´ ë³‘ê°€ ì •ì±…ì„ ì•ˆë‚´í•˜ëŠ” ì‹ìœ¼ë¡œ 
            í•œêµ­ì–´ HR ìš©ì–´ë¥¼ ì •í™•íˆ ì¸ì‹í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."""
        }
    
    def get_context_from_documents(self, user_input):
        """ì‚¬ìš©ì ì…ë ¥ê³¼ ê´€ë ¨ëœ HR ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        if not self.rag.documents:
            return ""
        
        # ì‚¬ìš©ì ì…ë ¥ì„ HR ìš©ì–´ë¡œ í™•ì¥
        expanded_query = self.expand_query_with_terms(user_input)
        
        # í™•ì¥ëœ ì¿¼ë¦¬ë¡œ ë¬¸ì„œ ê²€ìƒ‰
        similar_docs = self.rag.search_similar_documents(expanded_query, top_k=4)
        
        # ì›ë³¸ ì¿¼ë¦¬ë¡œë„ ê²€ìƒ‰í•´ì„œ ê²°ê³¼ í•©ì¹˜ê¸°
        if expanded_query != user_input:
            original_docs = self.rag.search_similar_documents(user_input, top_k=2)
            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ í•©ì¹˜ê¸°
            seen_contents = set()
            combined_docs = []
            for doc in similar_docs + original_docs:
                if doc['content'] not in seen_contents:
                    seen_contents.add(doc['content'])
                    combined_docs.append(doc)
            similar_docs = combined_docs[:4]  # ìµœëŒ€ 4ê°œë¡œ ì œí•œ
        
        if not similar_docs:
            return ""
        
        context = "=== ê´€ë ¨ HR ì •ì±… ë° ë¬¸ì„œ ===\n\n"
        for i, doc in enumerate(similar_docs):
            context += f"[ì°¸ê³ ë¬¸ì„œ {i+1}] {doc['metadata']['file_name']}:\n"
            context += f"{doc['content']}\n"
            context += f"(ê´€ë ¨ë„: {doc['similarity']:.0%})\n\n"
        
        context += "=== ìœ„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš” ===\n"
        return context, similar_docs
    
    def generate_response(self, user_input, conversation_history):
        """AI ì‘ë‹µ ìƒì„±"""
        if not self.client:
            return "âŒ OpenAI ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        # ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        context_result = self.get_context_from_documents(user_input)
        context = ""
        similar_docs = []
        
        if context_result:
            context, similar_docs = context_result
        
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [self.get_system_message()]
        
        # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 5ê°œë§Œ)
        for conv in conversation_history[-5:]:
            messages.append({"role": "user", "content": conv["user"]})
            messages.append({"role": "assistant", "content": conv["assistant"]})
        
        # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
        if context:
            enhanced_input = f"{context}\n\nì§ì› ì§ˆë¬¸: {user_input}"
        else:
            enhanced_input = user_input
        
        messages.append({"role": "user", "content": enhanced_input})
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                temperature=0.3,
                messages=messages,
                max_tokens=1200
            )
            
            ai_response = response.choices[0].message.content
            return ai_response, similar_docs
            
        except Exception as e:
            return f"âŒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", []

def main():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'app' not in st.session_state:
        st.session_state.app = HRHelpdeskWebApp()
    
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []
    
    if 'documents_loaded' not in st.session_state:
        st.session_state.documents_loaded = False
    
    # í—¤ë”
    st.title("ğŸ‘¥ HR í—¬í”„ë°ìŠ¤í¬")
    st.markdown("ì¸ì‚¬ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ğŸ˜Š")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        uploaded_files = st.file_uploader(
            "HR ê´€ë ¨ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['txt', 'pdf', 'docx', 'csv', 'json'],
            accept_multiple_files=True,
            help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        if uploaded_files and not st.session_state.documents_loaded:
            if st.button("ğŸ“š ë¬¸ì„œ ë¡œë“œ ë° ì„ë² ë”© ìƒì„±"):
                if st.session_state.app.rag.load_documents_from_files(uploaded_files):
                    if st.session_state.app.rag.create_embeddings():
                        st.session_state.documents_loaded = True
                        st.success("âœ… ë¬¸ì„œ ë¡œë“œ ë° ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
                        st.rerun()
        
        # ë¬¸ì„œ ìƒíƒœ í‘œì‹œ
        st.markdown("---")
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        
        if st.session_state.documents_loaded:
            st.success(f"ğŸ“š ë¡œë“œëœ ë¬¸ì„œ: {len(st.session_state.app.rag.documents)}ê°œ ì²­í¬")
        else:
            st.info("ğŸ“ ë¬¸ì„œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        if st.session_state.app.client:
            st.success("ğŸ¤– OpenAI ì—°ê²°: ì •ìƒ")
        else:
            st.error("âŒ OpenAI ì—°ê²°: ì‹¤íŒ¨")
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
        st.markdown("---")
        st.subheader("ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
        
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.conversation_history = []
            st.rerun()
        
        st.info(f"ëŒ€í™” ìˆ˜: {len(st.session_state.conversation_history)}")
        
        # ìì£¼ ë¬»ëŠ” ì§ˆë¬¸
        st.markdown("---")
        st.markdown("""
        <div class="quick-help">
        <h4>ğŸ” ìì£¼ ë¬»ëŠ” ì§ˆë¬¸</h4>
        <ul>
        <li>ğŸ’° "ê¸‰ì—¬ëª…ì„¸ì„œëŠ” ì–´ë””ì„œ í™•ì¸í•˜ë‚˜ìš”?"</li>
        <li>ğŸ–ï¸ "ì—°ì°¨ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"</li>
        <li>ğŸ¤’ "ë³‘ê°€ëŠ” ëª‡ ì¼ê¹Œì§€ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?"</li>
        <li>ğŸ’° "ì•¼ê·¼ìˆ˜ë‹¹ì€ ì–´ë–»ê²Œ ê³„ì‚°ë˜ë‚˜ìš”?"</li>
        <li>ğŸ "ë³µë¦¬í›„ìƒ ì œë„ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"</li>
        <li>ğŸ“ˆ "ì¸ì‚¬í‰ê°€ ê¸°ì¤€ì´ ê¶ê¸ˆí•´ìš”"</li>
        <li>ğŸ  "ì¬íƒê·¼ë¬´ ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”"</li>
        <li>ğŸ‘¶ "ì¶œì‚°íœ´ê°€ëŠ” ì–¸ì œë¶€í„° ì‚¬ìš©í•˜ë‚˜ìš”?"</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    st.markdown("---")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
    chat_container = st.container()
    
    with chat_container:
        for conv in st.session_state.conversation_history:
            # ì‚¬ìš©ì ë©”ì‹œì§€
            st.markdown(f"""
            <div class="chat-message user">
                <div class="avatar">ğŸ‘¤</div>
                <div class="message"><strong>ì§ì›:</strong><br>{conv['user']}</div>
            </div>
            """, unsafe_allow_html=True)
            
            # AI ì‘ë‹µ
            st.markdown(f"""
            <div class="chat-message bot">
                <div class="avatar">ğŸ‘¥</div>
                <div class="message"><strong>HR í—¬í”„ë°ìŠ¤í¬:</strong><br>{conv['assistant']}</div>
            </div>
            """, unsafe_allow_html=True)
            
            # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
            if 'sources' in conv and conv['sources']:
                with st.expander("ğŸ“‹ ì°¸ê³  ë¬¸ì„œ"):
                    for doc in conv['sources']:
                        st.write(f"ğŸ“„ **{doc['metadata']['file_name']}** (ê´€ë ¨ë„: {doc['similarity']:.0%})")
    
    # ì‚¬ìš©ì ì…ë ¥
    with st.form("chat_form", clear_on_submit=True):
        col1, col2 = st.columns([4, 1])
        
        with col1:
            user_input = st.text_input(
                "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
                placeholder="ì˜ˆ: ì—°ì°¨ ì‹ ì²­ ë°©ë²•ì´ ê¶ê¸ˆí•´ìš”, ë³‘ê°€ëŠ” ëª‡ ì¼ê¹Œì§€?, ì•¼ê·¼ìˆ˜ë‹¹ ê³„ì‚°ë²•",
                label_visibility="collapsed"
            )
        
        with col2:
            submitted = st.form_submit_button("ğŸ’¬ ì „ì†¡", use_container_width=True)
    
    # ë©”ì‹œì§€ ì²˜ë¦¬
    if submitted and user_input.strip():
        with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            response_data = st.session_state.app.generate_response(
                user_input, 
                st.session_state.conversation_history
            )
            
            if len(response_data) == 2:
                ai_response, similar_docs = response_data
            else:
                ai_response = response_data
                similar_docs = []
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            conversation_entry = {
                "user": user_input,
                "assistant": ai_response,
                "timestamp": datetime.now().isoformat(),
                "sources": similar_docs
            }
            
            st.session_state.conversation_history.append(conversation_entry)
            st.rerun()
    
    # í™˜ì˜ ë©”ì‹œì§€ (ëŒ€í™”ê°€ ì—†ì„ ë•Œë§Œ)
    if not st.session_state.conversation_history:
        st.markdown("""
        <div class="chat-message bot">
            <div class="avatar">ğŸ‘¥</div>
            <div class="message">
                <strong>HR í—¬í”„ë°ìŠ¤í¬:</strong><br>
                ì•ˆë…•í•˜ì„¸ìš”! HR í—¬í”„ë°ìŠ¤í¬ì…ë‹ˆë‹¤. ì¸ì‚¬ ê´€ë ¨ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š<br><br>
                ğŸ’¡ <strong>íŒ:</strong> ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ HR ê´€ë ¨ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            </div>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()